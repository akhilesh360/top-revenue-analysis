{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fd183e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# End-to-End Revenue Analysis\n",
    "\n",
    "This notebook performs a comprehensive analysis of the relationship between Time on Page (TOP) and Revenue.\n",
    "\n",
    "**Outputs:**\n",
    "- `figs/fig1_hexbin.png` - Hexbin plot with LOWESS trend\n",
    "- `figs/fig2_spline_uncontrolled.png` - Spline regression (uncontrolled)\n",
    "- `figs/fig3_marginal_effects.png` - Controlled marginal effects\n",
    "- `report/data_profile.json` - Data profiling and key statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52ce525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsmodels.api import add_constant\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "from patsy import dmatrix, build_design_matrices\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8767807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration and Setup\n",
    "# Adapted for the current workspace structure\n",
    "\n",
    "# Update paths to match your workspace structure\n",
    "DATA_PATH = \"../data/testdata.csv\"  # Relative to analysis folder\n",
    "OUT_DIR = \"..\"  # Root of the project\n",
    "FIG_DIR = os.path.join(OUT_DIR, \"figs\")\n",
    "REP_DIR = os.path.join(OUT_DIR, \"report\")\n",
    "\n",
    "# Create output directories if they don't exist\n",
    "os.makedirs(FIG_DIR, exist_ok=True)\n",
    "os.makedirs(REP_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Data path: {DATA_PATH}\")\n",
    "print(f\"Figures will be saved to: {FIG_DIR}\")\n",
    "print(f\"Reports will be saved to: {REP_DIR}\")\n",
    "print(f\"Data file exists: {os.path.exists(DATA_PATH)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba88527",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38550cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and clean the data\n",
    "raw = pd.read_csv(DATA_PATH)\n",
    "print(f\"Loaded {len(raw)} rows with {len(raw.columns)} columns\")\n",
    "print(\"Columns:\", list(raw.columns))\n",
    "\n",
    "initial_rows = len(raw)\n",
    "missing_counts = raw.isna().sum().to_dict()\n",
    "print(f\"\\nMissing values:\\n{pd.Series(missing_counts)}\")\n",
    "\n",
    "# Drop rows with missing revenue or top values\n",
    "df = raw.dropna(subset=[\"revenue\", \"top\"]).copy()\n",
    "after_drop_rows = len(df)\n",
    "print(f\"\\nAfter dropping missing revenue/top: {after_drop_rows} rows ({initial_rows - after_drop_rows} dropped)\")\n",
    "\n",
    "# Cast categorical variables\n",
    "for col in [\"browser\", \"platform\", \"site\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(\"category\")\n",
    "        print(f\"Cast {col} as category with {len(df[col].cat.categories)} levels\")\n",
    "\n",
    "# Display basic info\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"Data types:\\n{df.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0b23ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Winsorize outliers at 1%/99% percentiles\n",
    "winsor_thresholds = {}\n",
    "rows_winsorized = {}\n",
    "\n",
    "for col in [\"revenue\", \"top\"]:\n",
    "    # Calculate percentiles\n",
    "    lo, hi = df[col].quantile([0.01, 0.99])\n",
    "    winsor_thresholds[col] = (float(lo), float(hi))\n",
    "    \n",
    "    # Count rows that will be affected\n",
    "    rows_winsorized[col] = int(((df[col] < lo) | (df[col] > hi)).sum())\n",
    "    \n",
    "    # Apply winsorization\n",
    "    df[col] = np.clip(df[col], lo, hi)\n",
    "    \n",
    "    print(f\"{col}: winsorized {rows_winsorized[col]} rows at [{lo:.2f}, {hi:.2f}]\")\n",
    "\n",
    "# Create log-transformed revenue variable\n",
    "df[\"log_rev\"] = np.log1p(df[\"revenue\"])\n",
    "print(f\"\\nCreated log_rev variable (log(1 + revenue))\")\n",
    "\n",
    "# Show summary statistics\n",
    "print(f\"\\nSummary statistics after cleaning:\")\n",
    "print(df[[\"revenue\", \"top\", \"log_rev\"]].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a67179",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb110710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate EDA statistics\n",
    "eda_stats = {\n",
    "    \"revenue\": {\n",
    "        \"mean\": float(df[\"revenue\"].mean()),\n",
    "        \"median\": float(df[\"revenue\"].median()),\n",
    "        \"sd\": float(df[\"revenue\"].std()),\n",
    "    },\n",
    "    \"top\": {\n",
    "        \"mean\": float(df[\"top\"].mean()),\n",
    "        \"median\": float(df[\"top\"].median()),\n",
    "        \"sd\": float(df[\"top\"].std()),\n",
    "    },\n",
    "    \"corr_revenue_top\": float(df[[\"revenue\",\"top\"]].corr().iloc[0,1])\n",
    "}\n",
    "\n",
    "print(\"EDA Statistics:\")\n",
    "for var, stats in eda_stats.items():\n",
    "    if isinstance(stats, dict):\n",
    "        print(f\"{var}:\")\n",
    "        for stat, val in stats.items():\n",
    "            print(f\"  {stat}: {val:.3f}\")\n",
    "    else:\n",
    "        print(f\"{var}: {stats:.3f}\")\n",
    "\n",
    "# Generate Figure 1: Hexbin plot with LOWESS trend\n",
    "plt.figure(figsize=(7,5), dpi=150)\n",
    "hb = plt.hexbin(df[\"top\"], df[\"revenue\"], gridsize=40, mincnt=1)\n",
    "plt.colorbar(hb, label='Count')\n",
    "\n",
    "# Add LOWESS smoothing trend\n",
    "low = lowess(df[\"revenue\"], df[\"top\"], frac=0.2, return_sorted=True)\n",
    "plt.plot(low[:,0], low[:,1], 'r-', linewidth=2, label='LOWESS trend')\n",
    "\n",
    "plt.xlabel(\"Time on Page (TOP)\")\n",
    "plt.ylabel(\"Revenue\")\n",
    "plt.title(\"Revenue vs Time on Page (EDA)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "fig1_path = os.path.join(FIG_DIR, \"fig1_hexbin.png\")\n",
    "plt.savefig(fig1_path)\n",
    "print(f\"\\nSaved Figure 1: {fig1_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d8056f",
   "metadata": {},
   "source": [
    "## 3. Statistical Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b758ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for OLS regression with robust standard errors\n",
    "def fit_ols(y, X):\n",
    "    \"\"\"Fit OLS model with robust (HC1) standard errors\"\"\"\n",
    "    Xc = add_constant(X, has_constant=\"add\")\n",
    "    model = OLS(y, Xc).fit(cov_type=\"HC1\")  # robust SEs\n",
    "    return model\n",
    "\n",
    "# Model 1: revenue ~ top (simple linear relationship)\n",
    "print(\"Model 1: revenue ~ top\")\n",
    "m1 = fit_ols(df[\"revenue\"], df[[\"top\"]])\n",
    "print(m1.summary())\n",
    "print(f\"\\nModel 1 R-squared: {m1.rsquared:.4f}\")\n",
    "print(f\"TOP coefficient: {m1.params.get('top', float('nan')):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a064941f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: log1p(revenue) ~ spline(top, df=4) - Check for diminishing returns\n",
    "print(\"Model 2: log1p(revenue) ~ spline(top, df=4)\")\n",
    "X_spline = dmatrix(\"bs(top, df=4, degree=3, include_intercept=False)\", {\"top\": df[\"top\"]}, return_type=\"dataframe\")\n",
    "m2 = fit_ols(df[\"log_rev\"], X_spline)\n",
    "print(f\"Model 2 R-squared: {m2.rsquared:.4f}\")\n",
    "\n",
    "# Generate predictions for plotting\n",
    "top_grid = np.linspace(df[\"top\"].min(), df[\"top\"].max(), 200)\n",
    "Xgrid_spline = dmatrix(\"bs(top, df=4, degree=3, include_intercept=False)\", {\"top\": top_grid}, return_type=\"dataframe\")\n",
    "Xgrid_spline_c = add_constant(Xgrid_spline, has_constant=\"add\")\n",
    "pred2 = m2.get_prediction(Xgrid_spline_c)\n",
    "pred2_mean = pred2.predicted_mean\n",
    "pred2_ci = pred2.conf_int()\n",
    "\n",
    "# Generate Figure 2: Spline regression (uncontrolled)\n",
    "plt.figure(figsize=(7,5), dpi=150)\n",
    "plt.plot(top_grid, pred2_mean, 'b-', linewidth=2, label='Spline fit')\n",
    "plt.fill_between(top_grid, pred2_ci[:,0], pred2_ci[:,1], alpha=0.2, color='blue', label='95% CI')\n",
    "plt.xlabel(\"Time on Page (TOP)\")\n",
    "plt.ylabel(\"log(1 + Revenue)\")\n",
    "plt.title(\"Diminishing Returns Check (Spline, Uncontrolled)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "fig2_path = os.path.join(FIG_DIR, \"fig2_spline_uncontrolled.png\")\n",
    "plt.savefig(fig2_path)\n",
    "print(f\"\\nSaved Figure 2: {fig2_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a5d772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: log1p(revenue) ~ spline(top) + C(browser) + C(platform) + C(site)\n",
    "# This controls for other factors while examining the TOP effect\n",
    "print(\"Model 3: log1p(revenue) ~ spline(top) + controls\")\n",
    "\n",
    "design = dmatrix(\n",
    "    \"bs(top, df=4, degree=3, include_intercept=False) + C(browser) + C(platform) + C(site)\",\n",
    "    df,\n",
    "    return_type=\"dataframe\"\n",
    ")\n",
    "\n",
    "design_info = design.design_info\n",
    "m3 = fit_ols(df[\"log_rev\"], design)\n",
    "print(f\"Model 3 R-squared: {m3.rsquared:.4f}\")\n",
    "print(f\"Number of parameters: {len(m3.params)}\")\n",
    "\n",
    "# Show a summary of the controlled model\n",
    "print(f\"\\nControlled model summary:\")\n",
    "print(f\"AIC: {m3.aic:.2f}\")\n",
    "print(f\"BIC: {m3.bic:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5774bb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marginal Effects Analysis\n",
    "# Compare predictions at different TOP values while holding other factors constant\n",
    "\n",
    "def predict_logrev(model, top_values, df_ref):\n",
    "    \"\"\"Predict log(revenue) for given TOP values, holding other factors at reference levels\"\"\"\n",
    "    # Build a design matrix holding other factors at their reference (first category)\n",
    "    tmp = df_ref.copy()\n",
    "    tmp = tmp.iloc[:1].copy()  # single row template\n",
    "    tmp = pd.concat([tmp]*len(top_values), ignore_index=True)\n",
    "    tmp[\"top\"] = top_values\n",
    "    \n",
    "    # Set reference categories to the first levels\n",
    "    for col in [\"browser\",\"platform\",\"site\"]:\n",
    "        if col in tmp.columns and str(tmp[col].dtype) == \"category\":\n",
    "            tmp[col] = tmp[col].cat.categories[0]\n",
    "    \n",
    "    X = build_design_matrices([design_info], tmp)[0]\n",
    "    Xc = add_constant(X, has_constant=\"add\")\n",
    "    pred = model.get_prediction(Xc).predicted_mean\n",
    "    return pred\n",
    "\n",
    "# Generate predictions across TOP range\n",
    "top_vals = np.linspace(df[\"top\"].quantile(0.05), df[\"top\"].quantile(0.95), 120)\n",
    "log_pred = predict_logrev(m3, top_vals, df)\n",
    "\n",
    "# Generate Figure 3: Controlled marginal effects\n",
    "plt.figure(figsize=(7,5), dpi=150)\n",
    "plt.plot(top_vals, np.expm1(log_pred), 'g-', linewidth=2)\n",
    "plt.xlabel(\"Time on Page (TOP)\")\n",
    "plt.ylabel(\"Predicted Revenue (Controlled)\")\n",
    "plt.title(\"Controlled Marginal Effect of TOP\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "fig3_path = os.path.join(FIG_DIR, \"fig3_marginal_effects.png\")\n",
    "plt.savefig(fig3_path)\n",
    "print(f\"Saved Figure 3: {fig3_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b448857f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate key effect size: % change from mean TOP to mean + 1 SD\n",
    "mu = df[\"top\"].mean()\n",
    "sd = df[\"top\"].std()\n",
    "\n",
    "log_mu = predict_logrev(m3, np.array([mu]), df)[0]\n",
    "log_mu_sd = predict_logrev(m3, np.array([mu+sd]), df)[0]\n",
    "percent_change_mu_to_mu_sd = float(np.expm1(log_mu_sd - log_mu) * 100.0)\n",
    "\n",
    "print(f\"Key Effect Size:\")\n",
    "print(f\"Mean TOP: {mu:.2f}\")\n",
    "print(f\"Mean + 1 SD TOP: {mu + sd:.2f}\")\n",
    "print(f\"Predicted revenue increase from mean to mean+1SD: {percent_change_mu_to_mu_sd:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dafb5cb",
   "metadata": {},
   "source": [
    "## 4. Final Report Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a72c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive data profile and save results\n",
    "profile = {\n",
    "    \"initial_rows\": initial_rows,\n",
    "    \"rows_after_drop\": after_drop_rows,\n",
    "    \"n_columns\": raw.shape[1],\n",
    "    \"missing_counts\": missing_counts,\n",
    "    \"winsorized_thresholds\": winsor_thresholds,\n",
    "    \"rows_winsorized\": rows_winsorized,\n",
    "    \"eda_stats\": eda_stats,\n",
    "    \"m1_slope_top\": float(m1.params.get(\"top\", float(\"nan\"))),\n",
    "    \"m1_r2\": float(m1.rsquared),\n",
    "    \"m2_r2\": float(m2.rsquared),\n",
    "    \"m3_r2\": float(m3.rsquared),\n",
    "    \"controlled_effect_mu_to_mu_plus_1sd_percent\": percent_change_mu_to_mu_sd\n",
    "}\n",
    "\n",
    "# Save the profile to JSON\n",
    "profile_path = os.path.join(REP_DIR, \"data_profile.json\")\n",
    "with open(profile_path, \"w\") as f:\n",
    "    json.dump(profile, f, indent=2)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Data profile saved: {profile_path}\")\n",
    "print(f\"Figures saved:\")\n",
    "print(f\"  - {os.path.join(FIG_DIR, 'fig1_hexbin.png')}\")\n",
    "print(f\"  - {os.path.join(FIG_DIR, 'fig2_spline_uncontrolled.png')}\")\n",
    "print(f\"  - {os.path.join(FIG_DIR, 'fig3_marginal_effects.png')}\")\n",
    "print(f\"\\nKey Finding:\")\n",
    "print(f\"A 1 standard deviation increase in Time on Page is associated with a\")\n",
    "print(f\"{percent_change_mu_to_mu_sd:.2f}% increase in revenue (controlled for other factors).\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
